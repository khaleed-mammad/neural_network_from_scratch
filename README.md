# Neural Network from Scratch

This project implements a **basic neural network from scratch** using Python, focusing on **automatic differentiation**, **backpropagation**, and **training a simple model** without external deep learning frameworks. It also compares the implementation with PyTorch.

## üìå Features
- **Concepts of Derivatives & Backpropagation**
- **Custom `Value` Class for Autograd**
- **Graph Visualization of Computation Graph**
- **Manually Implemented Neural Network**
- **Training & Optimization on Artificial Data**
- **Comparison with PyTorch**

## üìÇ Project Structure
- **Concept of Derivatives**: Understanding derivatives and their role in machine learning.
- **Manual Backpropagation**: Implementing autograd from scratch.
- **Single Optimization Step**: Training a model using gradient descent.
- **Simple Neural Network**: Constructing a small neural net using custom autograd.
- **Automated Backpropagation**: Improving the backpropagation system.
- **Comparison with PyTorch**: Verifying correctness by comparing with PyTorch.
- **Training Demo**: Demonstration of training process on tiny dataset.

## ‚öôÔ∏è Installation
### **Dependencies**
Ensure you have Python installed along with the following packages:
```bash
pip install numpy matplotlib graphviz torch
